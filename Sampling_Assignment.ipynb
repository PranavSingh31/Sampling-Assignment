{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBUohPQLh1PbwA6/b50ppE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PranavSingh31/Sampling-Assignment/blob/main/Sampling_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.under_sampling import RandomUnderSampler, TomekLinks, NearMiss\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "djzmzrY2Lzh5"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "url = 'https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv'\n",
        "data = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "BQAIHKFML2sh"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into features and target\n",
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "mtVIYxVoL6ZH"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the z-value and margin of error for each sampling technique\n",
        "z = 1.96  # 95% confidence interval\n",
        "m = 0.05  # margin of error\n",
        "\n",
        "# Calculate the sample size for each sampling technique using the formula\n",
        "n1 = int(np.ceil((z**2 * 0.5 * 0.5) / (m**2)))\n",
        "n2 = int(np.ceil((z**2 * 0.05 * (1-0.05)) / (m**2)))\n",
        "n3 = int(np.ceil((z**2 * 0.05 * (1-0.05)) / (m**2)))\n",
        "n4 = int(np.ceil((z**2 * 0.05 * (1-0.05)) / (m**2)))\n",
        "n5 = int(np.ceil((z**2 * 0.05 * (1-0.05)) / (m**2)))"
      ],
      "metadata": {
        "id": "l5gNrJETMBLH"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sampling techniques and models\n",
        "sampler1 = RandomUnderSampler(sampling_strategy='majority', random_state=42)\n",
        "sampler2 = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
        "sampler3 = TomekLinks(sampling_strategy='majority')\n",
        "sampler4 = NearMiss(version=3, n_neighbors=3)\n",
        "sampler5 = SMOTE(sampling_strategy='minority', random_state=42)\n",
        "\n",
        "model1 = LogisticRegression(random_state=42,max_iter=750)\n",
        "model2 = ExtraTreesClassifier(random_state=80)\n",
        "model3 = RandomForestClassifier(random_state=42)\n",
        "model4 = SVC(random_state=42)\n",
        "model5 = DecisionTreeClassifier(random_state=42)"
      ],
      "metadata": {
        "id": "g2Q4vr5FMGju"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a dictionary to hold the sampling techniques and models\n",
        "samplers = {\n",
        "    'Sampling1': sampler1,\n",
        "    'Sampling2': sampler2,\n",
        "    'Sampling3': sampler3,\n",
        "    'Sampling4': sampler4,\n",
        "    'Sampling5': sampler5,\n",
        "}\n",
        "models = {\n",
        "    'Model 1': model1,\n",
        "    'Model 2': model2,\n",
        "    'Model 3': model3,\n",
        "    'Model 4': model4,\n",
        "    'Model 5': model5,\n",
        "}\n"
      ],
      "metadata": {
        "id": "d5CVZOR6MK5H"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate each model on each sampling technique\n",
        "results = {}\n",
        "for sampler_name, sampler in samplers.items():\n",
        "    if sampler_name == 'Sampling1':\n",
        "        n = n1\n",
        "    elif sampler_name == 'Sampling2':\n",
        "        n = n2\n",
        "    elif sampler_name == 'Sampling3':\n",
        "        n = n3\n",
        "    elif sampler_name == 'Sampling4':\n",
        "        n = n4\n",
        "    else:\n",
        "        n = n5\n",
        "\n",
        "    # Undersample or oversample the training data\n",
        "    X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
        "    \n",
        "    # Limit the resampled data to the sample size\n",
        "    if len(X_resampled) > n:\n",
        "        X_resampled = X_resampled[:n]\n",
        "        y_resampled = y_resampled[:n]\n",
        "    \n",
        "    for model_name, model in models.items():\n",
        "        # Train the model on the resampled data\n",
        "        model.fit(X_resampled, y_resampled)\n",
        "        \n",
        "        # Make predictions on the test data\n",
        "        y_pred = model.predict(X_test)\n",
        "        \n",
        "        # Calculate the accuracy score\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        \n",
        "        # Add the accuracy score to the results dictionary\n",
        "        if model_name in results:\n",
        "            results[model_name][sampler_name] = accuracy\n",
        "        else:\n",
        "            results[model_name] = {sampler_name: accuracy}"
      ],
      "metadata": {
        "id": "bNASCxurMQ99"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "H4Nh21yWGuz6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c9df8c-f49d-4348-88b1-83666b75c045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            "          Sample 1     Sample 2     Sample 3     Sample 4     Sample 5\n",
            "Model 1    0.5742       0.9935       0.9935       0.3742       0.9935   \n",
            "Model 2    0.7290       0.9935       0.9935       0.6129       0.9935   \n",
            "Model 3    0.7097       0.9935       0.9935       0.7677       0.9935   \n",
            "Model 4    0.6258       0.9935       0.9935       0.5161       0.9935   \n",
            "Model 5    0.5742       0.9806       0.9806       0.6968       0.9806   \n"
          ]
        }
      ],
      "source": [
        "# Print the results\n",
        "print('Results:')\n",
        "print('          Sample 1     Sample 2     Sample 3     Sample 4     Sample 5')\n",
        "for model_name, model_results in results.items():\n",
        "    print(model_name, end='')\n",
        "    for sampler_name in samplers.keys():\n",
        "        if sampler_name in model_results:\n",
        "            print(f'    {model_results[sampler_name]:.4f}   ', end='')\n",
        "        else:\n",
        "            print('              ', end='')\n",
        "    print() "
      ]
    }
  ]
}